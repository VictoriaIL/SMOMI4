{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab4_crop170.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6NaAD8zpv2Yv","colab_type":"code","outputId":"0d49aa2d-a4d2-407a-8186-45a1b5b14a80","executionInfo":{"status":"ok","timestamp":1592135913503,"user_tz":-180,"elapsed":24338,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c3bJlWt3Vq_G","colab_type":"code","outputId":"8e595d2c-cd5e-46da-d14d-2fae34237d1a","executionInfo":{"status":"ok","timestamp":1592136019509,"user_tz":-180,"elapsed":107615,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":860}},"source":["!pip3 uninstall tensorflow \n","!pip3 install tensorflow-gpu==1.14"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.2.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.2.0\n","Collecting tensorflow-gpu==1.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n","\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.29.0)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 51.4MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.2)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 58.3MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.5)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (47.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.0)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFBz8AdxWlQB","colab_type":"code","outputId":"12ea4edc-bc36-4583-c29c-54fc76a3f500","executionInfo":{"status":"ok","timestamp":1592136086575,"user_tz":-180,"elapsed":1695,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/СМОМИ/Лаба 4\")\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["images\tlab4_crop170.ipynb  logs  model.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IbvI6OmOimd9","colab_type":"code","outputId":"f803ee71-8898-470b-d363-d2411506ac18","executionInfo":{"status":"error","timestamp":1592146474713,"user_tz":-180,"elapsed":10372414,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["__author__ = 'Alexander Soroka, soroka.a.m@gmail.com'\n","__copyright__ = \"\"\"Copyright 2020 Alexander Soroka\"\"\"\n","\n","\n","import argparse\n","import glob\n","import numpy as np\n","import tensorflow as tf\n","import time\n","import math\n","from tensorflow.python import keras as keras\n","from keras.models import load_model\n","from numpy import asarray\n","import PIL\n","from PIL import Image\n","import random\n","\n","\n","LOG_DIR = 'logs'\n","SHUFFLE_BUFFER = 10\n","BATCH_SIZE = 8\n","NUM_CLASSES = 2\n","PARALLEL_CALLS=4\n","RESIZE_TO = 224\n","TRAINSET_SIZE = 5216\n","VALSET_SIZE=624\n","\n","\n","def parse_proto_example(proto):\n","    keys_to_features = {\n","        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n","        'image/class/label': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))\n","    }\n","    example = tf.parse_single_example(proto, keys_to_features)\n","    example['image'] = tf.image.decode_jpeg(example['image/encoded'], channels=3)\n","    example['image'] = tf.image.convert_image_dtype(example['image'], dtype=tf.float32)\n","    return example['image'], example['image/class/label']\n","\n","\n","def normalize(image, label):\n","    return tf.image.per_image_standardization(image), label\n","\n","def resize(image, label):\n","    return tf.image.resize_images(image, tf.constant([RESIZE_TO, RESIZE_TO])), label\n","\n","def create_dataset(filenames, batch_size):\n","    \"\"\"Create dataset from tfrecords file\n","    :tfrecords_files: Mask to collect tfrecords file of dataset\n","    :returns: tf.data.Dataset\n","    \"\"\"\n","    return tf.data.TFRecordDataset(filenames)\\\n","        .map(parse_proto_example)\\\n","        .map(resize)\\\n","        .map(normalize)\\\n","        .shuffle(buffer_size=5 * batch_size)\\\n","        .repeat()\\\n","        .batch(batch_size)\\\n","        .prefetch(2 * batch_size)\n","\n","def create_aug_dataset(filenames, batch_size):\n","    return tf.data.TFRecordDataset(filenames)\\\n","        .map(parse_proto_example)\\\n","        .map(augment)\\\n","        .map(resize)\\\n","        .map(normalize)\\\n","        .shuffle(buffer_size=5 * batch_size)\\\n","        .repeat()\\\n","        .batch(batch_size)\\\n","        .prefetch(2 * batch_size)\n","\n","def augment(image,label):\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    image = tf.image.random_crop(image, size=[170, 170, 3], seed=None, name=None)\n","    return image,label\n","\n","class Validation(tf.keras.callbacks.Callback):\n","    def __init__(self, log_dir, validation_files, batch_size):\n","        self.log_dir = log_dir\n","        self.validation_files = validation_files\n","        self.batch_size = batch_size\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        print('The average loss for epoch {} is {:7.2f} '.format(\n","            epoch, logs['loss']\n","        ))\n","\n","        validation_dataset = create_dataset(self.validation_files, self.batch_size)\n","        validation_images, validation_labels = validation_dataset.make_one_shot_iterator().get_next()\n","        validation_labels = tf.one_hot(validation_labels, NUM_CLASSES)\n","\n","        result = self.model.evaluate(\n","            validation_images,\n","            validation_labels,\n","            steps=int(np.ceil(VALSET_SIZE / float(BATCH_SIZE)))\n","        )\n","        callback = tf.keras.callbacks.TensorBoard(log_dir=self.log_dir, update_freq='epoch', batch_size=self.batch_size)\n","\n","        callback.set_model(self.model)\n","        callback.on_epoch_end(epoch, {\n","            'val_' + self.model.metrics_names[i]: v for i, v in enumerate(result)\n","        })\n","\n","\n","def build_model():\n","    model = keras.models.load_model('model.h5')\n","    model.trainable = True\n","    return model\n","\n","\n","def main():\n","    train_path = './images/train*'\n","    test_path = './images/test*'\n","    train_dataset = create_aug_dataset(glob.glob(train_path), BATCH_SIZE)\n","    train_images, train_labels = train_dataset.make_one_shot_iterator().get_next()\n","    train_labels = tf.one_hot(train_labels, NUM_CLASSES)\n","\n","\n","    model = build_model()\n","\n","    model.compile(\n","        optimizer=keras.optimizers.sgd(lr=1e-11, momentum=0.9),\n","        loss=tf.keras.losses.categorical_crossentropy,\n","        metrics=[tf.keras.metrics.categorical_accuracy],\n","        target_tensors=[train_labels]\n","    )\n","\n","    log_dir='{}/xray-{}'.format(LOG_DIR, time.time())\n","    model.fit(\n","        (train_images, train_labels),\n","        epochs=130,\n","        steps_per_epoch=int(np.ceil(TRAINSET_SIZE / float(BATCH_SIZE))),\n","        callbacks=[\n","            tf.keras.callbacks.TensorBoard(log_dir),\n","            Validation(log_dir, validation_files=glob.glob(test_path), batch_size=BATCH_SIZE)\n","        ]\n","    )\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-4-b119e8f633bf>:99: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","Epoch 1/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1266 - categorical_accuracy: 0.3049The average loss for epoch 0 is    0.13 \n","78/78 [==============================] - 14s 177ms/step - loss: 0.3276 - categorical_accuracy: 0.7099\n","652/652 [==============================] - 94s 144ms/step - loss: 0.1271 - categorical_accuracy: 0.3060\n","Epoch 2/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1233 - categorical_accuracy: 0.2993The average loss for epoch 1 is    0.12 \n","78/78 [==============================] - 11s 136ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2035\n","652/652 [==============================] - 81s 125ms/step - loss: 0.1231 - categorical_accuracy: 0.2991\n","Epoch 3/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1240 - categorical_accuracy: 0.3013The average loss for epoch 2 is    0.12 \n","78/78 [==============================] - 16s 210ms/step - loss: 0.3478 - categorical_accuracy: 0.5593\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1238 - categorical_accuracy: 0.3008\n","Epoch 4/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1267 - categorical_accuracy: 0.3099The average loss for epoch 3 is    0.13 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0873 - categorical_accuracy: 0.2933\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1272 - categorical_accuracy: 0.3108\n","Epoch 5/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1260 - categorical_accuracy: 0.3020The average loss for epoch 4 is    0.13 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.1354 - categorical_accuracy: 0.4471\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1265 - categorical_accuracy: 0.3029\n","Epoch 6/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1221 - categorical_accuracy: 0.2984The average loss for epoch 5 is    0.12 \n","78/78 [==============================] - 11s 136ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2019\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1219 - categorical_accuracy: 0.2979\n","Epoch 7/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1244 - categorical_accuracy: 0.2974The average loss for epoch 6 is    0.12 \n","78/78 [==============================] - 11s 139ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2019\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1242 - categorical_accuracy: 0.2972\n","Epoch 8/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1243 - categorical_accuracy: 0.3018The average loss for epoch 7 is    0.12 \n","78/78 [==============================] - 11s 147ms/step - loss: 0.1044 - categorical_accuracy: 0.2676\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1241 - categorical_accuracy: 0.3016\n","Epoch 9/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1261 - categorical_accuracy: 0.3065The average loss for epoch 8 is    0.13 \n","78/78 [==============================] - 13s 162ms/step - loss: 0.2474 - categorical_accuracy: 0.6106\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1266 - categorical_accuracy: 0.3075\n","Epoch 10/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1231 - categorical_accuracy: 0.3034The average loss for epoch 9 is    0.12 \n","78/78 [==============================] - 11s 138ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2003\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1229 - categorical_accuracy: 0.3029\n","Epoch 11/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1252 - categorical_accuracy: 0.2942The average loss for epoch 10 is    0.13 \n","78/78 [==============================] - 17s 223ms/step - loss: 0.3909 - categorical_accuracy: 0.6571\n","652/652 [==============================] - 87s 134ms/step - loss: 0.1250 - categorical_accuracy: 0.2937\n","Epoch 12/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 0.3003The average loss for epoch 11 is    0.12 \n","78/78 [==============================] - 12s 149ms/step - loss: 0.1485 - categorical_accuracy: 0.3125\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1247 - categorical_accuracy: 0.2998\n","Epoch 13/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1260 - categorical_accuracy: 0.3103The average loss for epoch 12 is    0.13 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0641 - categorical_accuracy: 0.3269\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1266 - categorical_accuracy: 0.3112\n","Epoch 14/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1234 - categorical_accuracy: 0.3038The average loss for epoch 13 is    0.12 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1232 - categorical_accuracy: 0.3035\n","Epoch 15/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1246 - categorical_accuracy: 0.2947The average loss for epoch 14 is    0.12 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 85s 131ms/step - loss: 0.1244 - categorical_accuracy: 0.2945\n","Epoch 16/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.2986The average loss for epoch 15 is    0.12 \n","78/78 [==============================] - 13s 160ms/step - loss: 0.1841 - categorical_accuracy: 0.3782\n","652/652 [==============================] - 89s 137ms/step - loss: 0.1246 - categorical_accuracy: 0.2981\n","Epoch 17/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1267 - categorical_accuracy: 0.3072The average loss for epoch 16 is    0.13 \n","78/78 [==============================] - 12s 149ms/step - loss: 0.1739 - categorical_accuracy: 0.4936\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1274 - categorical_accuracy: 0.3083\n","Epoch 18/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1232 - categorical_accuracy: 0.2957The average loss for epoch 17 is    0.12 \n","78/78 [==============================] - 11s 138ms/step - loss: 0.0059 - categorical_accuracy: 0.2019\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1230 - categorical_accuracy: 0.2952\n","Epoch 19/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1262 - categorical_accuracy: 0.2957The average loss for epoch 18 is    0.13 \n","78/78 [==============================] - 17s 217ms/step - loss: 0.3371 - categorical_accuracy: 0.7115\n","652/652 [==============================] - 88s 134ms/step - loss: 0.1265 - categorical_accuracy: 0.2962\n","Epoch 20/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1234 - categorical_accuracy: 0.3024The average loss for epoch 19 is    0.12 \n","78/78 [==============================] - 14s 174ms/step - loss: 0.2260 - categorical_accuracy: 0.4151\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1232 - categorical_accuracy: 0.3021\n","Epoch 21/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1259 - categorical_accuracy: 0.3034The average loss for epoch 20 is    0.13 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0069 - categorical_accuracy: 0.2067\n","652/652 [==============================] - 85s 131ms/step - loss: 0.1258 - categorical_accuracy: 0.3031\n","Epoch 22/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1233 - categorical_accuracy: 0.3065The average loss for epoch 21 is    0.12 \n","78/78 [==============================] - 12s 149ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 86s 131ms/step - loss: 0.1231 - categorical_accuracy: 0.3060\n","Epoch 23/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1243 - categorical_accuracy: 0.3024The average loss for epoch 22 is    0.12 \n","78/78 [==============================] - 11s 141ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1241 - categorical_accuracy: 0.3021\n","Epoch 24/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1239 - categorical_accuracy: 0.3024The average loss for epoch 23 is    0.12 \n","78/78 [==============================] - 14s 181ms/step - loss: 0.2581 - categorical_accuracy: 0.4792\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1237 - categorical_accuracy: 0.3020\n","Epoch 25/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1286 - categorical_accuracy: 0.3032The average loss for epoch 24 is    0.13 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0954 - categorical_accuracy: 0.3734\n","652/652 [==============================] - 84s 130ms/step - loss: 0.1291 - categorical_accuracy: 0.3041\n","Epoch 26/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1251 - categorical_accuracy: 0.2988The average loss for epoch 25 is    0.12 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0945 - categorical_accuracy: 0.2708\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1249 - categorical_accuracy: 0.2983\n","Epoch 27/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1257 - categorical_accuracy: 0.3097The average loss for epoch 26 is    0.13 \n","78/78 [==============================] - 15s 191ms/step - loss: 0.2611 - categorical_accuracy: 0.6138\n","652/652 [==============================] - 89s 136ms/step - loss: 0.1262 - categorical_accuracy: 0.3108\n","Epoch 28/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1250 - categorical_accuracy: 0.2953The average loss for epoch 27 is    0.12 \n","78/78 [==============================] - 13s 163ms/step - loss: 0.2285 - categorical_accuracy: 0.4679\n","652/652 [==============================] - 85s 131ms/step - loss: 0.1248 - categorical_accuracy: 0.2949\n","Epoch 29/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1232 - categorical_accuracy: 0.3041The average loss for epoch 28 is    0.12 \n","78/78 [==============================] - 11s 138ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1230 - categorical_accuracy: 0.3039\n","Epoch 30/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1240 - categorical_accuracy: 0.2974The average loss for epoch 29 is    0.12 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 81s 125ms/step - loss: 0.1238 - categorical_accuracy: 0.2972\n","Epoch 31/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 0.2967The average loss for epoch 30 is    0.12 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1245 - categorical_accuracy: 0.2962\n","Epoch 32/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1234 - categorical_accuracy: 0.3043The average loss for epoch 31 is    0.12 \n","78/78 [==============================] - 15s 194ms/step - loss: 0.3488 - categorical_accuracy: 0.5705\n","652/652 [==============================] - 88s 134ms/step - loss: 0.1232 - categorical_accuracy: 0.3041\n","Epoch 33/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1281 - categorical_accuracy: 0.3084The average loss for epoch 32 is    0.13 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0208 - categorical_accuracy: 0.2596\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1287 - categorical_accuracy: 0.3092\n","Epoch 34/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 0.3038The average loss for epoch 33 is    0.12 \n","78/78 [==============================] - 12s 159ms/step - loss: 0.1748 - categorical_accuracy: 0.3510\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1245 - categorical_accuracy: 0.3035\n","Epoch 35/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1271 - categorical_accuracy: 0.2997The average loss for epoch 34 is    0.13 \n","78/78 [==============================] - 14s 178ms/step - loss: 0.1819 - categorical_accuracy: 0.5192\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1276 - categorical_accuracy: 0.3008\n","Epoch 36/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1243 - categorical_accuracy: 0.2992The average loss for epoch 35 is    0.12 \n","78/78 [==============================] - 13s 164ms/step - loss: 0.2270 - categorical_accuracy: 0.4872\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1241 - categorical_accuracy: 0.2991\n","Epoch 37/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.3024The average loss for epoch 36 is    0.12 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1235 - categorical_accuracy: 0.3020\n","Epoch 38/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1235 - categorical_accuracy: 0.2974The average loss for epoch 37 is    0.12 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1233 - categorical_accuracy: 0.2972\n","Epoch 39/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1240 - categorical_accuracy: 0.3026The average loss for epoch 38 is    0.12 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1238 - categorical_accuracy: 0.3023\n","Epoch 40/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.3053The average loss for epoch 39 is    0.12 \n","78/78 [==============================] - 15s 195ms/step - loss: 0.3889 - categorical_accuracy: 0.6859\n","652/652 [==============================] - 86s 131ms/step - loss: 0.1246 - categorical_accuracy: 0.3052\n","Epoch 41/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 0.3003The average loss for epoch 40 is    0.12 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0010 - categorical_accuracy: 0.2035\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1245 - categorical_accuracy: 0.2998\n","Epoch 42/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.2974The average loss for epoch 41 is    0.12 \n","78/78 [==============================] - 14s 181ms/step - loss: 0.2471 - categorical_accuracy: 0.4696\n","652/652 [==============================] - 87s 133ms/step - loss: 0.1234 - categorical_accuracy: 0.2970\n","Epoch 43/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1256 - categorical_accuracy: 0.3078The average loss for epoch 42 is    0.13 \n","78/78 [==============================] - 12s 155ms/step - loss: 0.0987 - categorical_accuracy: 0.4038\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1262 - categorical_accuracy: 0.3089\n","Epoch 44/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.3034The average loss for epoch 43 is    0.12 \n","78/78 [==============================] - 12s 160ms/step - loss: 0.2110 - categorical_accuracy: 0.5176\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1236 - categorical_accuracy: 0.3033\n","Epoch 45/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1240 - categorical_accuracy: 0.3053The average loss for epoch 44 is    0.12 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2003\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1238 - categorical_accuracy: 0.3048\n","Epoch 46/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.3024The average loss for epoch 45 is    0.12 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2003\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1235 - categorical_accuracy: 0.3023\n","Epoch 47/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1235 - categorical_accuracy: 0.3028The average loss for epoch 46 is    0.12 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2003\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1233 - categorical_accuracy: 0.3025\n","Epoch 48/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1272 - categorical_accuracy: 0.3084The average loss for epoch 47 is    0.13 \n","78/78 [==============================] - 14s 183ms/step - loss: 0.3320 - categorical_accuracy: 0.7131\n","652/652 [==============================] - 88s 135ms/step - loss: 0.1278 - categorical_accuracy: 0.3092\n","Epoch 49/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.3026The average loss for epoch 48 is    0.12 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2003\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1234 - categorical_accuracy: 0.3023\n","Epoch 50/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1242 - categorical_accuracy: 0.3020The average loss for epoch 49 is    0.12 \n","78/78 [==============================] - 16s 210ms/step - loss: 0.3402 - categorical_accuracy: 0.5641\n","652/652 [==============================] - 88s 135ms/step - loss: 0.1240 - categorical_accuracy: 0.3016\n","Epoch 51/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1264 - categorical_accuracy: 0.3089The average loss for epoch 50 is    0.13 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0826 - categorical_accuracy: 0.2997\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1270 - categorical_accuracy: 0.3098\n","Epoch 52/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1263 - categorical_accuracy: 0.3009The average loss for epoch 51 is    0.13 \n","78/78 [==============================] - 12s 152ms/step - loss: 0.1370 - categorical_accuracy: 0.4631\n","652/652 [==============================] - 86s 131ms/step - loss: 0.1269 - categorical_accuracy: 0.3018\n","Epoch 53/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1234 - categorical_accuracy: 0.3013The average loss for epoch 52 is    0.12 \n","78/78 [==============================] - 11s 139ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2003\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1232 - categorical_accuracy: 0.3008\n","Epoch 54/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1245 - categorical_accuracy: 0.3088The average loss for epoch 53 is    0.12 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1987\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1244 - categorical_accuracy: 0.3083\n","Epoch 55/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1219 - categorical_accuracy: 0.3105The average loss for epoch 54 is    0.12 \n","78/78 [==============================] - 12s 148ms/step - loss: 0.1010 - categorical_accuracy: 0.2564\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1217 - categorical_accuracy: 0.3100\n","Epoch 56/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1278 - categorical_accuracy: 0.3028The average loss for epoch 55 is    0.13 \n","78/78 [==============================] - 13s 164ms/step - loss: 0.2565 - categorical_accuracy: 0.6122\n","652/652 [==============================] - 87s 134ms/step - loss: 0.1283 - categorical_accuracy: 0.3039\n","Epoch 57/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.3007The average loss for epoch 56 is    0.12 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1971\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1246 - categorical_accuracy: 0.3004\n","Epoch 58/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1241 - categorical_accuracy: 0.3045The average loss for epoch 57 is    0.12 \n","78/78 [==============================] - 18s 227ms/step - loss: 0.3942 - categorical_accuracy: 0.6603\n","652/652 [==============================] - 89s 137ms/step - loss: 0.1239 - categorical_accuracy: 0.3043\n","Epoch 59/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1249 - categorical_accuracy: 0.2999The average loss for epoch 58 is    0.12 \n","78/78 [==============================] - 12s 156ms/step - loss: 0.1479 - categorical_accuracy: 0.3045\n","652/652 [==============================] - 87s 134ms/step - loss: 0.1247 - categorical_accuracy: 0.2995\n","Epoch 60/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1271 - categorical_accuracy: 0.3101The average loss for epoch 59 is    0.13 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0658 - categorical_accuracy: 0.3317\n","652/652 [==============================] - 85s 131ms/step - loss: 0.1278 - categorical_accuracy: 0.3110\n","Epoch 61/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1244 - categorical_accuracy: 0.3059The average loss for epoch 60 is    0.12 \n","78/78 [==============================] - 11s 141ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1971\n","652/652 [==============================] - 84s 130ms/step - loss: 0.1242 - categorical_accuracy: 0.3054\n","Epoch 62/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1244 - categorical_accuracy: 0.2982The average loss for epoch 61 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1971\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1242 - categorical_accuracy: 0.2977\n","Epoch 63/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1221 - categorical_accuracy: 0.3041The average loss for epoch 62 is    0.12 \n","78/78 [==============================] - 13s 163ms/step - loss: 0.1786 - categorical_accuracy: 0.3590\n","652/652 [==============================] - 86s 133ms/step - loss: 0.1219 - categorical_accuracy: 0.3037\n","Epoch 64/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1259 - categorical_accuracy: 0.3103The average loss for epoch 63 is    0.13 \n","78/78 [==============================] - 12s 150ms/step - loss: 0.1785 - categorical_accuracy: 0.4872\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1264 - categorical_accuracy: 0.3113\n","Epoch 65/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1249 - categorical_accuracy: 0.3007The average loss for epoch 64 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0080 - categorical_accuracy: 0.2051\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1247 - categorical_accuracy: 0.3004\n","Epoch 66/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1250 - categorical_accuracy: 0.3030The average loss for epoch 65 is    0.13 \n","78/78 [==============================] - 17s 215ms/step - loss: 0.3405 - categorical_accuracy: 0.7131\n","652/652 [==============================] - 91s 139ms/step - loss: 0.1255 - categorical_accuracy: 0.3037\n","Epoch 67/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1241 - categorical_accuracy: 0.2992The average loss for epoch 66 is    0.12 \n","78/78 [==============================] - 13s 173ms/step - loss: 0.2177 - categorical_accuracy: 0.4183\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1239 - categorical_accuracy: 0.2989\n","Epoch 68/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1258 - categorical_accuracy: 0.3041The average loss for epoch 67 is    0.13 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0056 - categorical_accuracy: 0.2196\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1261 - categorical_accuracy: 0.3048\n","Epoch 69/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1229 - categorical_accuracy: 0.3022The average loss for epoch 68 is    0.12 \n","78/78 [==============================] - 11s 141ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1955\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1227 - categorical_accuracy: 0.3018\n","Epoch 70/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.2984The average loss for epoch 69 is    0.12 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1955\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1246 - categorical_accuracy: 0.2981\n","Epoch 71/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.3116The average loss for epoch 70 is    0.12 \n","78/78 [==============================] - 14s 182ms/step - loss: 0.2509 - categorical_accuracy: 0.4872\n","652/652 [==============================] - 87s 133ms/step - loss: 0.1235 - categorical_accuracy: 0.3112\n","Epoch 72/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1269 - categorical_accuracy: 0.3120The average loss for epoch 71 is    0.13 \n","78/78 [==============================] - 12s 152ms/step - loss: 0.0947 - categorical_accuracy: 0.3862\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1273 - categorical_accuracy: 0.3131\n","Epoch 73/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1230 - categorical_accuracy: 0.3045The average loss for epoch 72 is    0.12 \n","78/78 [==============================] - 12s 149ms/step - loss: 0.0883 - categorical_accuracy: 0.2500\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1228 - categorical_accuracy: 0.3041\n","Epoch 74/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1277 - categorical_accuracy: 0.3068The average loss for epoch 73 is    0.13 \n","78/78 [==============================] - 15s 195ms/step - loss: 0.2636 - categorical_accuracy: 0.6266\n","652/652 [==============================] - 91s 139ms/step - loss: 0.1282 - categorical_accuracy: 0.3077\n","Epoch 75/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1230 - categorical_accuracy: 0.3040The average loss for epoch 74 is    0.12 \n","78/78 [==============================] - 13s 168ms/step - loss: 0.2288 - categorical_accuracy: 0.4968\n","652/652 [==============================] - 87s 133ms/step - loss: 0.1228 - categorical_accuracy: 0.3035\n","Epoch 76/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1246 - categorical_accuracy: 0.3045The average loss for epoch 75 is    0.12 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1244 - categorical_accuracy: 0.3043\n","Epoch 77/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1252 - categorical_accuracy: 0.3011The average loss for epoch 76 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1250 - categorical_accuracy: 0.3006\n","Epoch 78/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1231 - categorical_accuracy: 0.3093The average loss for epoch 77 is    0.12 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1229 - categorical_accuracy: 0.3089\n","Epoch 79/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1234 - categorical_accuracy: 0.3053The average loss for epoch 78 is    0.12 \n","78/78 [==============================] - 15s 192ms/step - loss: 0.3426 - categorical_accuracy: 0.5849\n","652/652 [==============================] - 87s 133ms/step - loss: 0.1232 - categorical_accuracy: 0.3048\n","Epoch 80/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1265 - categorical_accuracy: 0.3053The average loss for epoch 79 is    0.13 \n","78/78 [==============================] - 12s 148ms/step - loss: 0.0284 - categorical_accuracy: 0.2516\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1270 - categorical_accuracy: 0.3064\n","Epoch 81/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1245 - categorical_accuracy: 0.3072The average loss for epoch 80 is    0.12 \n","78/78 [==============================] - 13s 163ms/step - loss: 0.1728 - categorical_accuracy: 0.3478\n","652/652 [==============================] - 86s 131ms/step - loss: 0.1244 - categorical_accuracy: 0.3069\n","Epoch 82/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1254 - categorical_accuracy: 0.3066The average loss for epoch 81 is    0.13 \n","78/78 [==============================] - 14s 175ms/step - loss: 0.1922 - categorical_accuracy: 0.4952\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1259 - categorical_accuracy: 0.3077\n","Epoch 83/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.2999The average loss for epoch 82 is    0.12 \n","78/78 [==============================] - 13s 160ms/step - loss: 0.2221 - categorical_accuracy: 0.4904\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1234 - categorical_accuracy: 0.2997\n","Epoch 84/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1245 - categorical_accuracy: 0.3028The average loss for epoch 83 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1243 - categorical_accuracy: 0.3025\n","Epoch 85/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1233 - categorical_accuracy: 0.3043The average loss for epoch 84 is    0.12 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1231 - categorical_accuracy: 0.3039\n","Epoch 86/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1231 - categorical_accuracy: 0.3045The average loss for epoch 85 is    0.12 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1230 - categorical_accuracy: 0.3043\n","Epoch 87/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1252 - categorical_accuracy: 0.2967The average loss for epoch 86 is    0.13 \n","78/78 [==============================] - 15s 192ms/step - loss: 0.3816 - categorical_accuracy: 0.6859\n","652/652 [==============================] - 87s 134ms/step - loss: 0.1250 - categorical_accuracy: 0.2962\n","Epoch 88/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1246 - categorical_accuracy: 0.3043The average loss for epoch 87 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0017 - categorical_accuracy: 0.1971\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1246 - categorical_accuracy: 0.3044\n","Epoch 89/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1252 - categorical_accuracy: 0.3007The average loss for epoch 88 is    0.12 \n","78/78 [==============================] - 14s 184ms/step - loss: 0.2447 - categorical_accuracy: 0.4696\n","652/652 [==============================] - 87s 134ms/step - loss: 0.1250 - categorical_accuracy: 0.3002\n","Epoch 90/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1278 - categorical_accuracy: 0.3093The average loss for epoch 89 is    0.13 \n","78/78 [==============================] - 12s 157ms/step - loss: 0.1047 - categorical_accuracy: 0.4006\n","652/652 [==============================] - 86s 131ms/step - loss: 0.1284 - categorical_accuracy: 0.3102\n","Epoch 91/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1241 - categorical_accuracy: 0.3007The average loss for epoch 90 is    0.12 \n","78/78 [==============================] - 12s 159ms/step - loss: 0.2131 - categorical_accuracy: 0.5064\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1240 - categorical_accuracy: 0.3002\n","Epoch 92/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1239 - categorical_accuracy: 0.3038The average loss for epoch 91 is    0.12 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1238 - categorical_accuracy: 0.3033\n","Epoch 93/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1258 - categorical_accuracy: 0.3022The average loss for epoch 92 is    0.13 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1256 - categorical_accuracy: 0.3018\n","Epoch 94/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1227 - categorical_accuracy: 0.3130The average loss for epoch 93 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1923\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1226 - categorical_accuracy: 0.3125\n","Epoch 95/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1265 - categorical_accuracy: 0.3026The average loss for epoch 94 is    0.13 \n","78/78 [==============================] - 14s 182ms/step - loss: 0.3317 - categorical_accuracy: 0.7356\n","652/652 [==============================] - 86s 133ms/step - loss: 0.1269 - categorical_accuracy: 0.3037\n","Epoch 96/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.3020The average loss for epoch 95 is    0.12 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1235 - categorical_accuracy: 0.3016\n","Epoch 97/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.3053The average loss for epoch 96 is    0.12 \n","78/78 [==============================] - 16s 211ms/step - loss: 0.3265 - categorical_accuracy: 0.5833\n","652/652 [==============================] - 88s 136ms/step - loss: 0.1235 - categorical_accuracy: 0.3048\n","Epoch 98/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1275 - categorical_accuracy: 0.3076The average loss for epoch 97 is    0.13 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0733 - categorical_accuracy: 0.3333\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1281 - categorical_accuracy: 0.3085\n","Epoch 99/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1261 - categorical_accuracy: 0.3111The average loss for epoch 98 is    0.13 \n","78/78 [==============================] - 12s 154ms/step - loss: 0.1390 - categorical_accuracy: 0.4551\n","652/652 [==============================] - 86s 133ms/step - loss: 0.1264 - categorical_accuracy: 0.3117\n","Epoch 100/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1241 - categorical_accuracy: 0.3045The average loss for epoch 99 is    0.12 \n","78/78 [==============================] - 12s 147ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1239 - categorical_accuracy: 0.3044\n","Epoch 101/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1228 - categorical_accuracy: 0.2965The average loss for epoch 100 is    0.12 \n","78/78 [==============================] - 11s 147ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 84s 130ms/step - loss: 0.1226 - categorical_accuracy: 0.2960\n","Epoch 102/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1245 - categorical_accuracy: 0.3028The average loss for epoch 101 is    0.12 \n","78/78 [==============================] - 12s 150ms/step - loss: 0.0931 - categorical_accuracy: 0.2516\n","652/652 [==============================] - 86s 131ms/step - loss: 0.1244 - categorical_accuracy: 0.3025\n","Epoch 103/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1279 - categorical_accuracy: 0.3045The average loss for epoch 102 is    0.13 \n","78/78 [==============================] - 13s 164ms/step - loss: 0.2534 - categorical_accuracy: 0.6234\n","652/652 [==============================] - 87s 133ms/step - loss: 0.1283 - categorical_accuracy: 0.3056\n","Epoch 104/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1244 - categorical_accuracy: 0.2984The average loss for epoch 103 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1242 - categorical_accuracy: 0.2981\n","Epoch 105/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.2997The average loss for epoch 104 is    0.12 \n","78/78 [==============================] - 17s 224ms/step - loss: 0.3859 - categorical_accuracy: 0.6715\n","652/652 [==============================] - 89s 136ms/step - loss: 0.1234 - categorical_accuracy: 0.2995\n","Epoch 106/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1258 - categorical_accuracy: 0.3068The average loss for epoch 105 is    0.13 \n","78/78 [==============================] - 12s 154ms/step - loss: 0.1396 - categorical_accuracy: 0.2965\n","652/652 [==============================] - 85s 131ms/step - loss: 0.1256 - categorical_accuracy: 0.3066\n","Epoch 107/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1256 - categorical_accuracy: 0.3091The average loss for epoch 106 is    0.13 \n","78/78 [==============================] - 12s 153ms/step - loss: 0.0677 - categorical_accuracy: 0.3301\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1262 - categorical_accuracy: 0.3100\n","Epoch 108/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1255 - categorical_accuracy: 0.3126The average loss for epoch 107 is    0.13 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1253 - categorical_accuracy: 0.3121\n","Epoch 109/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1246 - categorical_accuracy: 0.3049The average loss for epoch 108 is    0.12 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1245 - categorical_accuracy: 0.3044\n","Epoch 110/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1256 - categorical_accuracy: 0.3032The average loss for epoch 109 is    0.13 \n","78/78 [==============================] - 13s 164ms/step - loss: 0.1736 - categorical_accuracy: 0.3590\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1254 - categorical_accuracy: 0.3031\n","Epoch 111/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1264 - categorical_accuracy: 0.3080The average loss for epoch 110 is    0.13 \n","78/78 [==============================] - 12s 154ms/step - loss: 0.1873 - categorical_accuracy: 0.4872\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1270 - categorical_accuracy: 0.3090\n","Epoch 112/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 0.3105The average loss for epoch 111 is    0.12 \n","78/78 [==============================] - 11s 145ms/step - loss: 5.9196e-04 - categorical_accuracy: 0.1907\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1245 - categorical_accuracy: 0.3100\n","Epoch 113/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1255 - categorical_accuracy: 0.3086The average loss for epoch 112 is    0.13 \n","78/78 [==============================] - 17s 214ms/step - loss: 0.3393 - categorical_accuracy: 0.7179\n","652/652 [==============================] - 89s 136ms/step - loss: 0.1258 - categorical_accuracy: 0.3092\n","Epoch 114/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1241 - categorical_accuracy: 0.3013The average loss for epoch 113 is    0.12 \n","78/78 [==============================] - 14s 177ms/step - loss: 0.2149 - categorical_accuracy: 0.4151\n","652/652 [==============================] - 87s 133ms/step - loss: 0.1239 - categorical_accuracy: 0.3008\n","Epoch 115/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1267 - categorical_accuracy: 0.3130The average loss for epoch 114 is    0.13 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0083 - categorical_accuracy: 0.2196\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1267 - categorical_accuracy: 0.3133\n","Epoch 116/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1234 - categorical_accuracy: 0.3045The average loss for epoch 115 is    0.12 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1232 - categorical_accuracy: 0.3041\n","Epoch 117/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.2999The average loss for epoch 116 is    0.12 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1891\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1234 - categorical_accuracy: 0.2995\n","Epoch 118/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1249 - categorical_accuracy: 0.3011The average loss for epoch 117 is    0.12 \n","78/78 [==============================] - 14s 183ms/step - loss: 0.2490 - categorical_accuracy: 0.4728\n","652/652 [==============================] - 87s 133ms/step - loss: 0.1247 - categorical_accuracy: 0.3006\n","Epoch 119/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1274 - categorical_accuracy: 0.3020The average loss for epoch 118 is    0.13 \n","78/78 [==============================] - 12s 152ms/step - loss: 0.0986 - categorical_accuracy: 0.3910\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1280 - categorical_accuracy: 0.3027\n","Epoch 120/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1229 - categorical_accuracy: 0.3028The average loss for epoch 119 is    0.12 \n","78/78 [==============================] - 12s 148ms/step - loss: 0.0807 - categorical_accuracy: 0.2548\n","652/652 [==============================] - 85s 130ms/step - loss: 0.1227 - categorical_accuracy: 0.3027\n","Epoch 121/130\n","651/652 [============================>.] - ETA: 0s - loss: 0.1263 - categorical_accuracy: 0.3126The average loss for epoch 120 is    0.13 \n","78/78 [==============================] - 16s 201ms/step - loss: 0.2672 - categorical_accuracy: 0.6298\n","652/652 [==============================] - 91s 140ms/step - loss: 0.1269 - categorical_accuracy: 0.3137\n","Epoch 122/130\n","602/652 [==========================>...] - ETA: 5s - loss: 0.1201 - categorical_accuracy: 0.2915"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-b119e8f633bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-b119e8f633bf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         callbacks=[\n\u001b[1;32m    118\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         ]\n\u001b[1;32m    121\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# `ins` can be callable in tf.distribute.Strategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}